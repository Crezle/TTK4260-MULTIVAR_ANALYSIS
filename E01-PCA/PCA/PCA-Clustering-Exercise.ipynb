{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: Learn to do clustering and noise reduction in data using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import svd \n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    U, S, PTrans = svd(X, full_matrices=False)\n",
    "    Sigma = np.diag(S)\n",
    "    T=np.dot(U,Sigma)\n",
    "    P=PTrans.T\n",
    "    return T, Sigma, P #Score, Variace, Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(data):\n",
    "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(8, 8),\n",
    "                  cmap='binary', interpolation='nearest',\n",
    "                  clim=(0, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the original dimension of the data\n",
    "X=digits.data\n",
    "y=digits.target\n",
    "print(\"Shape of X\",X.shape)\n",
    "print(\"Shape of y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the original data\n",
    "plot_digits(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Dimensionality reduction: Conduct PCA on the the matrix $X$ to find out the dimension required to capture 80% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Your code here - find SS \"\"\"\n",
    "SS = None \n",
    "\n",
    "\"\"\" ---         ---\"\"\"\n",
    "explained_variance = (SS ** 2) / 4\n",
    "explained_variance_ratio = (explained_variance / explained_variance.sum())\n",
    "plt.plot(np.cumsum(explained_variance_ratio))\n",
    "plt.grid()\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Task 2: Clustering: Project the original data matrix X on the first two PCs and draw the scalar plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Your code here - find t1 and t2 \"\"\"\n",
    "t1 = None\n",
    "t2 = None\n",
    "\n",
    "\"\"\" ---         ---\"\"\"\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(t1, t2,\n",
    "            c=digits.target, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('Spectral', 10))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Denoising: Remove noise from the noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to the original data\n",
    "X=digits.data\n",
    "y=digits.target\n",
    "np.random.seed(42)\n",
    "noisy = np.random.normal(X, 4)\n",
    "plot_digits(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips: \n",
    "\n",
    "* Decompose the noisy data using PCA \n",
    "* Reconstruct the data using just a few dominant components.For eg. check the variance plot \n",
    "\n",
    "Since the nature of the noise is more or less similar across all the digits, they are not the fearues with enough variance to discriminate between the digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Your code here \"\"\"\n",
    "X_denoised = None\n",
    "\n",
    "\"\"\" ---         ---\"\"\"\n",
    "\n",
    "plot_digits(X_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Study the impact of normalization of the dataset before conducting PCA. Discuss if it is critical to normalize this particular data compared to the dataset in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" Your code here \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" ---         ---\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smarthouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "430b629fc8318725e27907a539c84fb1944b0eecd3339434d3f68b0f2caf5d78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
